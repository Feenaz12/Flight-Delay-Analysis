# -*- coding: utf-8 -*-
"""train_model.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aky8_xCkD7q8Bz47F6Shw88zWYEdnEWp
"""

from google.colab import drive
drive.mount('/content/drive')

# train_model.py

# 1. Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer

# 2. Load cleaned data
file_path = "/content/drive/MyDrive/Masai/MASAI-PROJECTS/flights_cleaned_sample.csv"
df = pd.read_csv(file_path)

# Sample dataset to reduce memory usage
flights_sample = df.sample(n=200000, random_state=42)
print("Sampled dataset shape:", flights_sample.shape)


# 3. Define Features & Target
X = df.drop(['ARRIVAL_DELAY','Delayed','FL_DATE','YEAR','MONTH','DAY','DAY_OF_WEEK','SCHEDULED_DEPARTURE'], axis=1, errors='ignore')
y = df['Delayed']

# Keep only numeric columns
X = X.select_dtypes(include=np.number)

# 4. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

#  Handle missing values
imputer = SimpleImputer(strategy='median')
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Replace any remaining NaNs with 0
X_train = np.nan_to_num(X_train, nan=0)
X_test = np.nan_to_num(X_test, nan=0)

# 5. Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# 6. Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=500),
    "Random Forest": RandomForestClassifier(n_estimators=10 , max_depth=8,random_state=42,n_jobs=-1),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

# 7. Train & Evaluate Models
for name, model in models.items():
    print(f"\n=== Training {name} ===")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Recall: {recall_score(y_test, y_pred):.4f}")
    print(f"F1 Score: {f1_score(y_test, y_pred):.4f}")
    print(f"ROC-AUC: {roc_auc_score(y_test, model.predict_proba(X_test)[:,1]):.4f}")
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {name}")
    plt.show()

import os
import joblib

# Create the folder if it doesn't exist
os.makedirs("/content/drive/MyDrive/Masai/MASAI-PROJECTS/models", exist_ok=True)

# Save the model
best_model = RandomForestClassifier(n_estimators=10, max_depth=8, random_state=42, n_jobs=-1)
best_model.fit(X_train, y_train)
joblib.dump(best_model, '/content/drive/MyDrive/Masai/MASAI-PROJECTS/models/best_model_rf.pkl')

print("Best model saved as best_model_rf.pkl")

