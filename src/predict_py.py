# -*- coding: utf-8 -*-
"""Predict.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o7sa61tkpy8BOulC4P3rZ9tLs8EWHb_J
"""

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# predict.py

# 1. Import Libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import joblib

# 2. Load the saved model
model_path = "/content/drive/MyDrive/Masai/MASAI-PROJECTS/models/best_model_rf.pkl"
best_model = joblib.load(model_path)
print("Model loaded successfully!")

# 3. Load new flight data
new_data_path = "/content/drive/MyDrive/Masai/MASAI-PROJECTS/new_flights.csv"
new_flights = pd.read_csv(new_data_path)
print("New flights data loaded. Shape:", new_flights.shape)

# 4. Preprocess new data (same as training)
# Drop irrelevant columns
X_new = new_flights.drop(['ARRIVAL_DELAY','Delayed','FL_DATE','YEAR','MONTH','DAY','DAY_OF_WEEK','SCHEDULED_DEPARTURE'], axis=1, errors='ignore')

# Keep only numeric columns
X_new = X_new.select_dtypes(include=np.number)

# Handle missing values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='median')
X_new = imputer.fit_transform(X_new)

# Replace remaining NaNs with 0
X_new = np.nan_to_num(X_new, nan=0)

# Scale features
scaler = StandardScaler()
X_new = scaler.fit_transform(X_new)

# 5. Predict
predictions = best_model.predict(X_new)
pred_proba = best_model.predict_proba(X_new)[:,1]

# 6. Save predictions
output = new_flights.copy()
output['Predicted_Delay'] = predictions
output['Delay_Probability'] = pred_proba

import os

output_dir = "/content/drive/MyDrive/Masai/MASAI-PROJECTS/data"

# Create folder if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

output_path = os.path.join(output_dir, "new_flights_predictions.csv")
output.to_csv(output_path, index=False)
print(f"Predictions saved to {output_path}")

